{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/Wauplin/setfit@dont-use-deprecated-dataset-filter\n",
      "  Cloning https://github.com/Wauplin/setfit (to revision dont-use-deprecated-dataset-filter) to c:\\users\\s7\\appdata\\local\\temp\\pip-req-build-lntk9s6x\n",
      "  Resolved https://github.com/Wauplin/setfit to commit 74bfc124b79c3c2820c465817c5aaa34dafdc5a7\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: datasets>=2.3.0 in c:\\users\\s7\\appdata\\roaming\\python\\python311\\site-packages (from setfit==1.1.0.dev0) (2.19.0)\n",
      "Requirement already satisfied: sentence-transformers>=2.2.1 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from setfit==1.1.0.dev0) (3.0.1)\n",
      "Requirement already satisfied: evaluate>=0.3.0 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from setfit==1.1.0.dev0) (0.4.2)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from setfit==1.1.0.dev0) (0.23.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from setfit==1.1.0.dev0) (1.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\s7\\appdata\\roaming\\python\\python311\\site-packages (from setfit==1.1.0.dev0) (24.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from datasets>=2.3.0->setfit==1.1.0.dev0) (3.16.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from datasets>=2.3.0->setfit==1.1.0.dev0) (2.1.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from datasets>=2.3.0->setfit==1.1.0.dev0) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from datasets>=2.3.0->setfit==1.1.0.dev0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from datasets>=2.3.0->setfit==1.1.0.dev0) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\s7\\appdata\\roaming\\python\\python311\\site-packages (from datasets>=2.3.0->setfit==1.1.0.dev0) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\s7\\appdata\\roaming\\python\\python311\\site-packages (from datasets>=2.3.0->setfit==1.1.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from datasets>=2.3.0->setfit==1.1.0.dev0) (4.66.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from datasets>=2.3.0->setfit==1.1.0.dev0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\s7\\appdata\\roaming\\python\\python311\\site-packages (from datasets>=2.3.0->setfit==1.1.0.dev0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets>=2.3.0->setfit==1.1.0.dev0) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\s7\\appdata\\roaming\\python\\python311\\site-packages (from datasets>=2.3.0->setfit==1.1.0.dev0) (3.9.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from datasets>=2.3.0->setfit==1.1.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\s7\\appdata\\roaming\\python\\python311\\site-packages (from huggingface_hub>=0.21.0->setfit==1.1.0.dev0) (4.11.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from sentence-transformers>=2.2.1->setfit==1.1.0.dev0) (4.39.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\s7\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers>=2.2.1->setfit==1.1.0.dev0) (2.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from sentence-transformers>=2.2.1->setfit==1.1.0.dev0) (1.14.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from sentence-transformers>=2.2.1->setfit==1.1.0.dev0) (10.4.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from scikit-learn->setfit==1.1.0.dev0) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from scikit-learn->setfit==1.1.0.dev0) (3.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\s7\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets>=2.3.0->setfit==1.1.0.dev0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\s7\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets>=2.3.0->setfit==1.1.0.dev0) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from aiohttp->datasets>=2.3.0->setfit==1.1.0.dev0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from aiohttp->datasets>=2.3.0->setfit==1.1.0.dev0) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\s7\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets>=2.3.0->setfit==1.1.0.dev0) (1.9.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from requests>=2.19.0->datasets>=2.3.0->setfit==1.1.0.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from requests>=2.19.0->datasets>=2.3.0->setfit==1.1.0.dev0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from requests>=2.19.0->datasets>=2.3.0->setfit==1.1.0.dev0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\s7\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->datasets>=2.3.0->setfit==1.1.0.dev0) (2024.2.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\s7\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.11.0->sentence-transformers>=2.2.1->setfit==1.1.0.dev0) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\s7\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.11.0->sentence-transformers>=2.2.1->setfit==1.1.0.dev0) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\s7\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.11.0->sentence-transformers>=2.2.1->setfit==1.1.0.dev0) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\s7\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.62.1->datasets>=2.3.0->setfit==1.1.0.dev0) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=2.2.1->setfit==1.1.0.dev0) (2024.7.24)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=2.2.1->setfit==1.1.0.dev0) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=2.2.1->setfit==1.1.0.dev0) (0.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\s7\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets>=2.3.0->setfit==1.1.0.dev0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from pandas->datasets>=2.3.0->setfit==1.1.0.dev0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from pandas->datasets>=2.3.0->setfit==1.1.0.dev0) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\s7\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.3.0->setfit==1.1.0.dev0) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\s7\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.2.1->setfit==1.1.0.dev0) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\s7\\appdata\\roaming\\python\\python311\\site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.2.1->setfit==1.1.0.dev0) (1.3.0)\n",
      "Building wheels for collected packages: setfit\n",
      "  Building wheel for setfit (setup.py): started\n",
      "  Building wheel for setfit (setup.py): finished with status 'done'\n",
      "  Created wheel for setfit: filename=setfit-1.1.0.dev0-py3-none-any.whl size=76021 sha256=7cbdfbdde440233b7caaf902662ae02bb722fd498fc645e718068dc9e10300d2\n",
      "  Stored in directory: C:\\Users\\S7\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-zifxn414\\wheels\\9b\\c6\\d4\\c5980aa4b36b3f7032573a9b19b6881e9f375e15901cacbabf\n",
      "Successfully built setfit\n",
      "Installing collected packages: setfit\n",
      "  Attempting uninstall: setfit\n",
      "    Found existing installation: setfit 1.0.3\n",
      "    Uninstalling setfit-1.0.3:\n",
      "      Successfully uninstalled setfit-1.0.3\n",
      "Successfully installed setfit-1.1.0.dev0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/Wauplin/setfit 'C:\\Users\\S7\\AppData\\Local\\Temp\\pip-req-build-lntk9s6x'\n",
      "  Running command git checkout -b dont-use-deprecated-dataset-filter --track origin/dont-use-deprecated-dataset-filter\n",
      "  branch 'dont-use-deprecated-dataset-filter' set up to track 'origin/dont-use-deprecated-dataset-filter'.\n",
      "  Switched to a new branch 'dont-use-deprecated-dataset-filter'\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/Wauplin/setfit@dont-use-deprecated-dataset-filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setfit import SetFitModel, Trainer, SetFitTrainer, TrainingArguments, sample_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import re\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import f1_score\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('10_reviews_No_stop.csv' , index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BusinessId</th>\n",
       "      <th>review_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>comment</th>\n",
       "      <th>creation_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60202</td>\n",
       "      <td>364189</td>\n",
       "      <td>1</td>\n",
       "      <td>كنت اتعامل معهم اسعارهم ارخص لكن اخر مره حصلت ...</td>\n",
       "      <td>2024-05-11 05:56:29.327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60202</td>\n",
       "      <td>356203</td>\n",
       "      <td>1</td>\n",
       "      <td>عدم المصداقيه في اسعار المنتجات</td>\n",
       "      <td>2024-03-06 08:08:24.190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BusinessId  review_id  rating  \\\n",
       "0       60202     364189       1   \n",
       "1       60202     356203       1   \n",
       "\n",
       "                                             comment            creation_date  \n",
       "0  كنت اتعامل معهم اسعارهم ارخص لكن اخر مره حصلت ...  2024-05-11 05:56:29.327  \n",
       "1                    عدم المصداقيه في اسعار المنتجات  2024-03-06 08:08:24.190  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'label'] = np.where(df['rating'].isin([0, 1, 2]), 'Negative', 'Positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'comment' : 'text'} , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['text' , 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>كنت اتعامل معهم اسعارهم ارخص لكن اخر مره حصلت ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>عدم المصداقيه في اسعار المنتجات</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>المتجر سي جدا في مصداقيته في بيانات البضاعه وا...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>لا يوجد</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>لا يوجد</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62879</th>\n",
       "      <td>اكثر مايميز المتجر سرعه الرد والتوصيل السريع و...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62880</th>\n",
       "      <td>التعامل مع متجر توليب تجربه تستحق اعادتها اكثر...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62881</th>\n",
       "      <td>تجربتي معها جمييله وانسانه ذوق واخلاق ومتعاونه...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62882</th>\n",
       "      <td>متجر توليب جميل جدا والتعامل اجمل</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62883</th>\n",
       "      <td>لا يوجد</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62884 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     label\n",
       "0      كنت اتعامل معهم اسعارهم ارخص لكن اخر مره حصلت ...  Negative\n",
       "1                        عدم المصداقيه في اسعار المنتجات  Negative\n",
       "2      المتجر سي جدا في مصداقيته في بيانات البضاعه وا...  Negative\n",
       "3                                                لا يوجد  Negative\n",
       "4                                                لا يوجد  Negative\n",
       "...                                                  ...       ...\n",
       "62879  اكثر مايميز المتجر سرعه الرد والتوصيل السريع و...  Positive\n",
       "62880  التعامل مع متجر توليب تجربه تستحق اعادتها اكثر...  Positive\n",
       "62881  تجربتي معها جمييله وانسانه ذوق واخلاق ومتعاونه...  Positive\n",
       "62882                  متجر توليب جميل جدا والتعامل اجمل  Positive\n",
       "62883                                            لا يوجد  Positive\n",
       "\n",
       "[62884 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>كنت اتعامل معهم اسعارهم ارخص لكن اخر مره حصلت ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>عدم المصداقيه في اسعار المنتجات</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label\n",
       "0  كنت اتعامل معهم اسعارهم ارخص لكن اخر مره حصلت ...  Negative\n",
       "1                    عدم المصداقيه في اسعار المنتجات  Negative"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['label'].isin(['Positive', 'Negative'])]\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36893, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_length'] = df['text'].map(lambda a: len(a))\n",
    "df = df[(df['text_length']<200) & (df['text_length']>10)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Positive    35626\n",
       "Negative     1267\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'text_length', '__index_level_0__'],\n",
       "    num_rows: 36893\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(df)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\S7\\anaconda3\\envs\\Twuaiq\\Lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n",
      "c:\\Users\\S7\\anaconda3\\envs\\Twuaiq\\Lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n",
      "c:\\Users\\S7\\anaconda3\\envs\\Twuaiq\\Lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    }
   ],
   "source": [
    "# Simulate the few-shot regime by sampling 8 examples per class\n",
    "train_dataset = sample_dataset(dataset, label_column=\"label\", num_samples=8)\n",
    "eval_dataset = sample_dataset(dataset, label_column=\"label\", num_samples=50)\n",
    "test_dataset = sample_dataset(dataset, label_column=\"label\", num_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'text_length', '__index_level_0__'],\n",
       "    num_rows: 16\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'text_length', '__index_level_0__'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'text_length', '__index_level_0__'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\S7\\anaconda3\\envs\\Twuaiq\\Lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  url,\n",
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load a SetFit model from Hub\n",
    "model = SetFitModel.from_pretrained(\n",
    "    \"sentence-transformers/paraphrase-mpnet-base-v2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 16/16 [00:00<00:00, 2285.49 examples/s]\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    batch_size=16,\n",
    "    num_epochs=4,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    metric=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num unique pairs = 144\n",
      "  Batch size = 16\n",
      "  Num epochs = 4\n",
      "  Total optimization steps = 36\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/36 [00:01<?, ?it/s]\n",
      "\n",
      "\u001b[A                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.4134, 'learning_rate': 5e-06, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 124/319 [19:51<30:17,  9.32s/it]"
     ]
    }
   ],
   "source": [
    "# Train and evaluate\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.44.2\n",
      "0.24.6\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import huggingface_hub\n",
    "\n",
    "print(transformers.__version__)\n",
    "print(huggingface_hub.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.44.2\n",
      "Uninstalling transformers-4.44.2:\n",
      "  Successfully uninstalled transformers-4.44.2\n",
      "Collecting transformers==4.39.0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\S7\\anaconda3\\envs\\Twuaiq\\Lib\\site-packages\\~okenizers'.\n",
      "  You can safely remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached transformers-4.39.0-py3-none-any.whl.metadata (134 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from transformers==4.39.0) (3.16.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from transformers==4.39.0) (0.23.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from transformers==4.39.0) (2.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\s7\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.39.0) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from transformers==4.39.0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from transformers==4.39.0) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\users\\s7\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.39.0) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.39.0)\n",
      "  Downloading tokenizers-0.15.2-cp311-none-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from transformers==4.39.0) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from transformers==4.39.0) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.0) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\s7\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.0) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\s7\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers==4.39.0) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from requests->transformers==4.39.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from requests->transformers==4.39.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\s7\\anaconda3\\envs\\twuaiq\\lib\\site-packages (from requests->transformers==4.39.0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\s7\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers==4.39.0) (2024.2.2)\n",
      "Using cached transformers-4.39.0-py3-none-any.whl (8.8 MB)\n",
      "Downloading tokenizers-0.15.2-cp311-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.2 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 4.7 MB/s eta 0:00:00\n",
      "Installing collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.19.1\n",
      "    Uninstalling tokenizers-0.19.1:\n",
      "      Successfully uninstalled tokenizers-0.19.1\n",
      "Successfully installed tokenizers-0.15.2 transformers-4.39.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y huggingface_hub\n",
    "!pip install huggingface_hub==0.23.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
